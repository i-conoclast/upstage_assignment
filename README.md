
## 1. Summary


## 2. Experimental Results


## 3. Instructions

**Environment Settings**

- íŒŒì´ì¬ ë²„ì „ ê´€ë¦¬ ë„êµ¬ë¡œ `pyenv` ì‚¬ìš© (.python-version íŒŒì¼ ì°¸ê³ )
- ì˜ì¡´ì„± ê´€ë¦¬ ë„êµ¬ë¡œ `Poetry` ì‚¬ìš©
- ìƒì„¸ ë‚´ìš©ì€ Usage Instructions - 2) Environment Setup ì°¸ê³ 

**Code Structure**

```
ğŸ“¦ upstage_assignment
â”œâ”€Â data
â”‚Â Â â”œâ”€Â train.csv (ì›ë³¸)
â”‚Â Â â”œâ”€Â train_data.csv
â”‚Â Â â”œâ”€Â valid_data.csv
â”‚Â Â â””â”€Â test_data.csv
â”œâ”€Â models
â”œâ”€Â notebooks
â”‚Â Â â””â”€Â plots
â”œâ”€Â outputs
â”œâ”€Â src
â”‚Â Â â”œâ”€Â tools
â”‚Â Â â”‚Â Â â”œâ”€Â __init__.py
â”‚Â Â â”‚Â Â â”œâ”€Â dict_label_to_num.pkl
â”‚Â Â â”‚Â Â â”œâ”€Â dict_num_to_label.pkl
â”‚Â Â â”‚Â Â â””â”€Â utils.py
â”‚Â Â â”œâ”€Â config.py
â”‚Â Â â”œâ”€Â dataset.py
â”‚Â Â â”œâ”€Â inference.py
â”‚Â Â â”œâ”€Â loss.py
â”‚Â Â â”œâ”€Â metrics.py
â”‚Â Â â”œâ”€Â model.py
â”‚Â Â â””â”€Â train.py
â”œâ”€Â train.sh
â”œâ”€Â inference.sh
â”œâ”€Â README.md
â”œâ”€Â .python_version
â”œâ”€Â poetry.lock
â””â”€Â pyproject.toml
```

**Usage Instructions**

1) Data Preparation
    - data/ ë””ë ‰í† ë¦¬ì— train_data.csv, valid_data.csv, test_data.csv íŒŒì¼ ì¤€ë¹„
        - ê¸°ì¡´ train.csvë¥¼ ì‚¬ìš©í•˜ì—¬ sklearnì˜ train_test_split í•¨ìˆ˜ë¥¼ í†µí•´ train_data.csvì™€ valid_data.csv ìƒì„±
        ```
        train, valid = train_test_split(train_data, test_size=0.2, 
        stratify=train_data["label"])
        
        train.reset_index(drop=True, inplace=True)
        valid.reset_index(drop=True, inplace=True)
        
        train.to_csv("data/train_data.csv", index=False)
        valid.to_csv("data/valid_data.csv", index=False)
        ```
2) Environment Setup
    - pyenv ì„¤ì¹˜ í›„ ì§„í–‰
        ```
        pyenv install 3.10.13
        pyenv local 3.10.13
        ```

    - poetry ì„¤ì¹˜ í›„ ì§„í–‰

        ```
        poetry install # ì˜ì¡´ì„± ì„¤ì¹˜
        poetry shell # ê°€ìƒí™˜ê²½ í™œì„±í™”
        ```

    - `pyproject.toml` íŒŒì¼ ë‚´ìš©

        ```
        [tool.poetry]
        name = "upstage-assignment"
        version = "0.1.0"
        description = ""
        authors = ["Your Name <you@example.com>"]
        readme = "README.md"

        [tool.poetry.dependencies]
        python = "^3.10"
        requests = "^2.32.3"
        pandas = "^2.2.3"
        tqdm = "^4.67.1"
        torch = "^2.5.1"
        transformers = "^4.47.1"
        scikit-learn = "^1.6.0"
        numpy = "^2.2.0"


        [build-system]
        requires = ["poetry-core"]
        build-backend = "poetry.core.masonry.api"
        ```
    
    - (ì„ íƒ) pyenvì˜ íŒŒì´ì¬ ë²„ì „ì„ poetryê°€ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •
        ```
        poetry env use 3.10.13
        ```


3) Model Training
    ```
    bash train.sh
    ```

    OR

    ```
    python src/train.py \
    --train_file data/train_data.csv \
    --valid_file data/valid_data.csv \
    --model_name_or_path klue/roberta-large \
    --max_length 128 \
    --batch_size 16 \
    --num_epochs 10 \
    --learning_rate 3e-5 \
    --use_cuda True \
    --use_entity_markers True \
    --use_entity_types True \
    --use_span_pooling True \
    --dropout 0.1 \
    --label2id_path utils/dict_label_to_num.pkl \
    --id2label_path utils/dict_num_to_label.pkl \
    --model_dir models \
    --output_dir outputs \
    --focal_loss \
    --label_smoothing 0.09 \
    --alpha 1.0 \
    --gamma 2.0 \
    ```

    - ì„¸ë¶€ê°’ì€ ì¡°ì • ê°€ëŠ¥
    - í•™ìŠµ ê²°ê³¼ëŠ” models/ ë””ë ‰í† ë¦¬ì— ì €ì¥

4) Model Inference
    ```
    bash inference.sh
    ```

    OR

    ```
    python src/inference.py \
    --model_file models/{ëª¨ë¸ëª…}.pth \
    --output_dir outputs \
    --test_file data/test_data.csv \
    ```

    - ì¶”ë¡  ê²°ê³¼ëŠ” csv íŒŒì¼ë¡œ outputs/ ë””ë ‰í† ë¦¬ì— ì €ì¥
        - id, pred_label, probs ì»¬ëŸ¼ í¬í•¨
        - idëŠ” ì›ë³¸ ë°ì´í„°ì˜ idì™€ ë™ì¼
        - pred_labelì€ ì˜ˆì¸¡ ë ˆì´ë¸”
        - probsëŠ” ì˜ˆì¸¡ í™•ë¥ 

## 4. Approach

**Exploratory Data Analysis(EDA)**

**Model & Architecture**

**Training/Evaluation Scheme**

**Literature & Relevant Works**

**Future Work**